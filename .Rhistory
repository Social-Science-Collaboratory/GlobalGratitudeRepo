<<<<<<< Updated upstream
"Long term orientation",
"Indulgence"
)
))
View(results)
results <- do.call(rbind, results) %>% as.data.frame()
colnames(results)
colnames(results)
results <- sapply(
X = seq_len(nrow(expanded.list)),
simplify = FALSE,
FUN = function(i) {
df <- DF %>%
select(
expanded.list$out.list[i],
expanded.list$mod.list[i]
)
names(df) <- c("x", "y")
# Pearson correlation
cor.est <- cor(
x = df$x,
y = df$y,
use = "pairwise.complete.obs",
method = "pearson"
)
# Bayes factor
bf.est <- correlationBF(
x = df$x,
y = df$y
)
# Correlation test (gives CI + p)
cor.test.res <- cor.test(
df$x, df$y,
method = "pearson",
use = "pairwise.complete.obs"
)
data.frame(
outcome = expanded.list$out.list[i],
moderator = expanded.list$mod.list[i],
cor.est = cor.est,
bf = extractBF(bf.est)$bf,
ci.lower = cor.test.res$conf.int[1],
ci.upper = cor.test.res$conf.int[2]
)
}
) %>% do.call(rbind, .)
colnames(results)
results <- results %>%
=======
as.formula(paste0(
x,
"~ condition + (1 + condition | lab)"
)),
data = DF
)
emm <- emmeans(m,
pairwise ~ condition,
adjust = "none",
pbkrtest.limit = 99999
)
return(list(
m = summary(m),
emm = emm
))
}
)
DF <- readRDS(file = here("data/final-data", "globalgratitude_final_cleaned.Rds"))
View(DF)
style_project()
DF <- readRDS(file = here("data/final-data", "globalgratitude_final_cleaned.Rds"))
DF_test <- readRDS(file = here("data/final-data", "globalgratitude_final_cleaned_old.Rds"))
identical(df1, df2)
identical(DF_test, DF)
View(DF_test)
cols_test <- colnames(DF_test)
cols_main <- colnames(DF)
# Columns in DF_test but not in DF
extra_in_test <- setdiff(cols_test, cols_main)
# Columns in DF but not in DF_test
extra_in_main <- setdiff(cols_main, cols_test)
list(
only_in_DF_test = extra_in_test,
only_in_DF = extra_in_main
)
extra_in_test <- setdiff(names(DF_test), names(DF))
# Remove them from DF_test
DF_test_clean <- DF_test %>%
select(-all_of(extra_in_test))
identical(DF, DF_test)
identical(DF, DF_test_clean)
extra_in_test <- setdiff(names(DF_test), names(DF))
# Remove them from DF_test
DF_test_clean <- DF_test %>%
select(-all_of(extra_in_test))
identical(DF, DF_test_clean)
all(names(DF_test) == names(DF))
all(names(DF_test_clean) == names(DF))
View(DF_test_clean)
View(DF)
# Rows in DF_test but not in DF
rows_in_test_not_DF <- anti_join(DF_test, DF)
# Rows in DF but not in DF_test
rows_in_DF_not_test <- anti_join(DF, DF_test)
# Put results in a list
list(
only_in_DF_test = rows_in_test_not_DF,
only_in_DF = rows_in_DF_not_test
)
View(rows_in_DF_not_test)
View(rows_in_test_not_DF)
# Rows in DF_test but not in DF
rows_in_test_not_DF <- anti_join(DF_test, DF)
# Rows in DF but not in DF_test
rows_in_DF_not_test <- anti_join(DF, DF_test_cleaned)
# Rows in DF_test but not in DF
rows_in_test_not_DF <- anti_join(DF_test, DF)
# Rows in DF but not in DF_test
rows_in_DF_not_test <- anti_join(DF, DF_test_clean)
# Put results in a list
list(
only_in_DF_test = rows_in_test_not_DF,
only_in_DF = rows_in_DF_not_test
)
diff_rows <- full_join(DF_test_clean %>% mutate(.source = "DF_test"),
DF %>% mutate(.source = "DF")) %>%
distinct() %>%
group_by(across(-.source)) %>%
filter(n() == 1) %>%   # keep rows that appear only in one dataset
ungroup()
View(diff_rows)
# Chunk 1
# install packages
source("setup.R")
# Chunk 2
# fetch USA_02b data
USA_02b <-
read.csv(file = here(
"data/raw-data",
"USA_02b_raw_unharmonized.csv"
))
# change the condition column
USA_02b <-
USA_02b %>%
mutate(condition = case_when(
condition == 1 ~ "measure",
condition == 2 ~ "events",
condition == 3 ~ "int.events",
condition == 5 ~ "list",
condition == 6 ~ "letter",
condition == 7 ~ "text",
condition == 8 ~ "hk.list",
condition == 9 ~ "sub",
condition == 11 ~ "god.letter",
TRUE ~ as.character(condition)
))
# change the condition_type column
USA_02b <-
USA_02b %>%
mutate(condition_type = case_when(
condition_type == 1 ~ "control",
condition_type == 2 ~ "intervention",
TRUE ~ as.character(condition_type)
))
# Remove the color columns (results are inaccurate due to survey error)
USA_02b <-
USA_02b %>%
select(-color_task_red_6, -color_task_yellow_1, -color_task_blue_1)
# Save the processed data to CSV
write.csv(USA_02b,
file = here(
"data/raw-data",
"USA_02b_raw_harmonized.csv"
)
)
# Chunk 3
# fetch main survey data
data_main <-
readRDS(file = here(
"data/raw-data",
"globalgratitude_final.Rds"
)) %>%
select(StartDate:pageNo)
# fetch the USA_02b (harmonized) survey data
data_USA_02b <-
read.csv(file = here(
"data/raw-data",
"USA_02b_raw_harmonized.csv"
) %>%
select(StartDate:pageNo) %>%
rename("events_list" = "control_list"))
# fetch main survey data
data_main <-
readRDS(file = here(
"data/raw-data",
"globalgratitude_final.Rds"
)) %>%
select(StartDate:pageNo)
# fetch the USA_02b (harmonized) survey data
data_USA_02b <-
read.csv(file = here(
"data/raw-data",
"USA_02b_raw_harmonized.csv"
) %>%
select(StartDate:pageNo)
# fetch the USA_02c survey data
data_USA_02c <-
# fetch main survey data
data_main <-
readRDS(file = here(
"data/raw-data",
"globalgratitude_final.Rds"
)) %>%
select(StartDate:pageNo)
# fetch the USA_02b (harmonized) survey data
data_USA_02b <-
read.csv(file = here(
"data/raw-data",
"USA_02b_raw_harmonized.csv"
) %>%
select(StartDate:pageNo))
# fetch main survey data
data_main <-
readRDS(file = here(
"data/raw-data",
"globalgratitude_final.Rds"
)) %>%
select(StartDate:pageNo)
# fetch the USA_02b (harmonized) survey data
data_USA_02b <-
read.csv(file = here(
"data/raw-data",
"USA_02b_raw_harmonized.csv"
)) %>%
select(StartDate:pageNo)
# fetch the USA_02c survey data
data_USA_02c <-
read.csv(file = here(
"data/raw-data",
"USA_02c.csv"
)) %>%
select(StartDate:pageNo)
# match columns
data_main <- data_main %>%
mutate(across(names(data_USA_02c), ~ {
# matching character columns
if (is.character(data_USA_02c[[cur_column()]])) {
return(as.character(.))
}
# matching numeric or integer columns
else if (is.numeric(data_USA_02c[[cur_column()]])) {
return(as.numeric(.))
} else {
return(.)
}
}))
# combine CSV files
data <-
bind_rows(
data_main,
data_USA_02c
)
data <-
bind_rows(
data,
data_USA_02b
)
# clean data
data_cleaned <-
data %>%
# removed test links
filter(
DistributionChannel != "preview",
# 4/22/2024 TUR_01 used real link for testing purposes
ResponseId != "R_42KUGZSS76NgWH7",
ResponseId != "R_4W4EXfgeyk1rCYF",
ResponseId != "R_45Z862EIfzYcin4",
ResponseId != "R_7BhJx9Ci7THupmF",
ResponseId != "R_42Lv9fg5qi9V9xm",
ResponseId != "R_2kFa26mh78uevnz",
ResponseId != "R_4DRThnH8LgbEvM8",
ResponseId != "R_4r1kAEqQCo1PNn6",
ResponseId != "R_4GQErqyYDlRWVwZ",
ResponseId != "R_4SGF0GCHSHIN0ls",
ResponseId != "R_6Pndj5c7sr1pcU3",
ResponseId != "R_8lQxsY2ITg7HKh1",
ResponseId != "R_8HXsI5PQftiJUYk",
ResponseId != "R_8iVWI3CN49ACiUp",
# 6/6/2024 Removed USA_01 duplicate data
ResponseId != "R_6rDfD5u84z6WufT",
# 11/21/2024 Removed DZA_01 test data
ResponseId != "R_4ioYJK1zR2FgR4R",
ResponseId != "R_4OvlyOmeTsmLpFn",
ResponseId != "R_4BA1gbglSYnVyDK"
) %>%
# removed incomplete surveys
filter(
consent == 1,
Progress >= 95,
lab != "",
condition_type != "NA",
lab != "NA"
) %>%
select(StartDate:pageNo) # Remove non-relevant columns
# change the 'incentive' column from "volunteer" to "paid" for NOR_01 participants after 11/19/2024
data_cleaned <- data_cleaned %>%
mutate(
StartDate = as.POSIXct(StartDate, format = "%m/%d/%Y %H:%M"),
incentive = if_else(lab == "NOR_01" &
StartDate > as.POSIXct("11/19/2024 0:00",
format = "%m/%d/%Y%H:%M"
),
"paid", incentive
)
)
# fix age data where wrong info is inputted
data_cleaned <- data_cleaned %>%
mutate(age = if_else(age > 99,
2024 - age,
age
))
# rename interventions and controls
data_cleaned <-
data_cleaned %>%
mutate(condition = case_when(
condition == "god.letter" ~ "divine.grat",
condition == "hk.list" ~ "naikan",
condition == "sub" ~ "mental.sub",
TRUE ~ condition
))
# save dataset
saveRDS(data_cleaned,
file = here(
"data/final-data",
"globalgratitude_final_cleaned.Rds"
)
)
# fetch survey
DF <- readRDS(file = here("data/final-data", "globalgratitude_final_cleaned.Rds"))
DF <- DF %>%
rowwise() %>%
>>>>>>> Stashed changes
mutate(
`cor.est` = as.numeric(`cor.est`),
`cor.est` = round(`cor.est`, 2),
bf = as.numeric(bf),
logbf = round(log(bf), 2),
ci.lower = round(as.numeric(ci.lower), 2),
ci.upper = round(as.numeric(ci.upper), 2)
)
expanded.list <-
expand_grid(
out.list,
mod.list
)
results <- sapply(
X = seq_len(nrow(expanded.list)),
simplify = FALSE,
FUN = function(i) {
df <- DF %>%
select(
expanded.list$out.list[i],
expanded.list$mod.list[i]
)
names(df) <- c("x", "y")
# Pearson correlation
cor.est <- cor(
x = df$x,
y = df$y,
use = "pairwise.complete.obs",
method = "pearson"
)
# Bayes factor
bf.est <- correlationBF(
x = df$x,
y = df$y
)
# Correlation test (gives CI + p)
cor.test.res <- cor.test(
df$x, df$y,
method = "pearson",
use = "pairwise.complete.obs"
)
data.frame(
outcome = expanded.list$out.list[i],
moderator = expanded.list$mod.list[i],
cor.est = cor.est,
bf = extractBF(bf.est)$bf,
ci.lower = cor.test.res$conf.int[1],
ci.upper = cor.test.res$conf.int[2]
)
}
) %>% do.call(rbind, .)
results <- sapply(
X = seq_len(nrow(expanded.list)),
simplify = FALSE,
FUN = function(i) {
df <- DF %>%
select(
expanded.list$out.list[i],
expanded.list$mod.list[i]
)
names(df) <- c("x", "y")
# Pearson correlation
cor.est <- cor(
x = df$x,
y = df$y,
use = "pairwise.complete.obs",
method = "pearson"
)
# Bayes factor
bf.est <- correlationBF(
x = df$x,
y = df$y
)
# Correlation test (gives CI + p)
cor.test.res <- cor.test(
df$x, df$y,
method = "pearson",
use = "pairwise.complete.obs"
)
data.frame(
outcome = expanded.list$out.list[i],
moderator = expanded.list$mod.list[i],
cor.est = cor.est,
bf = extractBF(bf.est)$bf,
ci.lower = cor.test.res$conf.int[1],
ci.upper = cor.test.res$conf.int[2]
)
}
)
View(results)
results <-
do.call(rbind, results) %>%
as.data.frame() %>%
mutate(
cor.est = as.numeric(cor.est),
cor.est = round(cor.est, 2),
bf = as.numeric(bf),
logbf = log(bf),
logbf = round(logbf, 2),
ci.lower = round(as.numeric(ci.lower), 2),
ci.upper = round(as.numeric(ci.upper), 2)
)
View(results)
results <-
do.call(rbind, results) %>%
as.data.frame() %>%
mutate(
cor.est = as.numeric(cor.est),
cor.est = round(cor.est, 2),
bf = as.numeric(bf),
logbf = log(bf),
logbf = round(logbf, 2),
ci.lower = round(as.numeric(ci.lower), 2),
ci.upper = round(as.numeric(ci.upper), 2)
) %>%
<<<<<<< Updated upstream
# clean aesthetics
mutate(outcome = factor(outcome,
levels = c(
"pa_effect_size",
"na_effect_size",
"optimistic_effect_size",
"ls_effect_size",
"envy_effect_size",
"indebted_effect_size"
),
labels = c(
"Positive affect",
"Negative affect",
"Optimism",
"Life satisfaction",
"Envy",
"Indebtedness"
)
)) %>%
mutate(moderator = factor(moderator,
levels = c(
"individualism",
"tightness",
"relational_mobility",
"resmobility",
"responsibilism",
"relig_mean",
"mean_GDP",
"power.distance",
"motivation",
"uncertainty.avoidance",
"long.term.orientation",
"indulgence"
),
labels = c(
"Individualism",
"Tightness",
"Relational mobility",
"Residential mobility",
"Responsibilism",
"Religiosity",
"GDP",
"Power distance",
"Motivation",
"Uncertainty avoidance",
"Long term orientation",
"Indulgence"
)
))
out.list <-
c(
"pa_effect_size",
"na_effect_size",
"optimistic_effect_size",
"ls_effect_size",
"envy_effect_size",
"indebted_effect_size"
)
mod.list <-
c(
"relational_mobility",
"responsibilism",
"tightness",
"relig_mean",
"mean_GDP",
"resmobility",
"power.distance",
"individualism",
"motivation",
"uncertainty.avoidance",
"long.term.orientation",
"indulgence"
)
expanded.list <-
expand_grid(
out.list,
mod.list
)
results <- sapply(
X = seq_len(nrow(expanded.list)),
simplify = FALSE,
FUN = function(i) {
df <- DF %>%
select(
expanded.list$out.list[i],
expanded.list$mod.list[i]
)
names(df) <- c("x", "y")
# Pearson correlation
cor.est <- cor(
x = df$x,
y = df$y,
use = "pairwise.complete.obs",
method = "pearson"
)
# Bayes factor
bf.est <- correlationBF(
x = df$x,
y = df$y
)
# Correlation test (gives CI + p)
cor.test.res <- cor.test(
df$x, df$y,
method = "pearson",
use = "pairwise.complete.obs"
)
data.frame(
outcome = expanded.list$out.list[i],
moderator = expanded.list$mod.list[i],
cor.est = cor.est,
bf = extractBF(bf.est)$bf,
ci.lower = cor.test.res$conf.int[1],
ci.upper = cor.test.res$conf.int[2]
)
}
)
# combine list
results <-
do.call(rbind, results) %>%
as.data.frame() %>%
mutate(
cor.est = as.numeric(cor.est),
cor.est = round(cor.est, 2),
bf = as.numeric(bf),
logbf = log(bf),
logbf = round(logbf, 2),
ci.lower = round(as.numeric(ci.lower), 2),
ci.upper = round(as.numeric(ci.upper), 2)
) %>%
# clean aesthetics
mutate(outcome = factor(outcome,
levels = c(
"pa_effect_size",
"na_effect_size",
"optimistic_effect_size",
"ls_effect_size",
"envy_effect_size",
"indebted_effect_size"
),
labels = c(
"Positive affect",
"Negative affect",
"Optimism",
"Life satisfaction",
"Envy",
"Indebtedness"
)
)) %>%
mutate(moderator = factor(moderator,
levels = c(
"individualism",
"tightness",
"relational_mobility",
"resmobility",
"responsibilism",
"relig_mean",
"mean_GDP",
"power.distance",
"motivation",
"uncertainty.avoidance",
"long.term.orientation",
"indulgence"
),
labels = c(
"Individualism",
"Tightness",
"Relational mobility",
"Residential mobility",
"Responsibilism",
"Religiosity",
"GDP",
"Power distance",
"Motivation",
"Uncertainty avoidance",
"Long term orientation",
"Indulgence"
)
))
# minor edit to label
results <- results %>%
mutate(cor.lab = paste0(
"paste(",
"italic(r), ' = ",
cor.est,
"')"
))
# restructure
results <- results %>%
mutate(
outcome = fct_reorder(outcome, -logbf),
moderator = fct_reorder(moderator, -logbf)
=======
ungroup() %>%
drop_na(
gratitude_mean, pa_mean, optimistic_mean, na_mean,
indebted_mean, envy_mean, ls_mean, guilty, ladder, ss_mean
)
DF <- DF %>%
mutate(country = case_when(
lab == "POL_01" ~ "Poland",
lab == "POL_02" ~ "Poland",
lab == "DNK_01" ~ "Denmark",
lab == "TUR_01" ~ "Turkey",
lab == "MYS_01" ~ "Malaysia",
lab == "USA_01" ~ "United States",
lab == "USA_02" ~ "United States",
lab == "USA_02b" ~ "United States",
lab == "USA_02c" ~ "United States",
lab == "NGA_01" ~ "Nigeria",
lab == "NGA_02" ~ "Nigeria",
lab == "CAN_01" ~ "Canada",
lab == "FRA_01" ~ "France",
lab == "AUS_01" ~ "Australia",
lab == "CHL_01" ~ "Chile",
lab == "DEU_01" ~ "Germany",
lab == "GRC_01" ~ "Greece",
lab == "HUN_01" ~ "Hungary",
lab == "ISR_01" ~ "Israel",
lab == "IRL_01" ~ "Ireland",
lab == "MEX_01" ~ "Mexico",
lab == "ITA_01" ~ "Italy",
lab == "PRT_01" ~ "Portugal",
lab == "BRA_01" ~ "Brazil",
lab == "NLD_01" ~ "Netherlands",
lab == "GBR_01" ~ "United Kingdom",
lab == "ESP_01" ~ "Spain",
lab == "ZAF_01" ~ "South Africa",
lab == "KOR_01" ~ "South Korea",
lab == "SWE_01" ~ "Sweden",
lab == "IND_01" ~ "India",
lab == "COL_01" ~ "Colombia",
lab == "CHN_01" ~ "China",
lab == "KAZ_01" ~ "Kazakhstan",
lab == "NOR_01" ~ "Norway",
lab == "JPN_01" ~ "Japan",
lab == "GHA_01" ~ "Ghana",
lab == "THA_01" ~ "Thailand",
lab == "MKD_01" ~ "Macedonia",
TRUE ~ NA_character_
)) %>%
filter(!is.na(country))
DF <- DF %>% select(country, condition, condition_type, guilty, ladder, gratitude_mean:ss_mean)
# create lists
unique_labs <- unique(DF$country)
condition_names <- c("list", "letter", "text", "naikan", "mental.sub", "divine.grat")
variables <- c(
"pa_mean", "na_mean", "optimistic_mean", "ls_mean", "ladder",
"envy_mean", "indebted_mean", "gratitude_mean", "guilty", "ss_mean"
)
# set levels
DF$condition <- factor(DF$condition)
DF$condition <- factor(DF$condition, levels = c(
"measure", "events", "int.events",
"list", "letter", "text", "naikan", "mental.sub", "divine.grat"
))
DF$condition_type <- factor(DF$condition_type, levels = c("control", "intervention"))
# initialize data frame
unique_country_results_df <- data.frame()
# compute Cohen's d and variance
compute_effect_sizes <- function(lab_name, control_cond, intervention_cond) {
# subset data
country_data <- DF %>% filter(country == lab_name)
control_subset <- country_data %>% filter(condition == control_cond)
intervention_subset <- country_data %>% filter(condition == intervention_cond)
# calculate variance
calc_var <- function(d, n1, n2) {
se_d <- sqrt((n1 + n2) / (n1 * n2) + d^2 / (2 * (n1 + n2)))
return(se_d^2)
}
# loop through each measure
effects <- sapply(variables, function(measure) {
d_result <- effsize::cohen.d(
intervention_subset[[measure]],
control_subset[[measure]],
pooled = TRUE,
hedges.correction = TRUE
>>>>>>> Stashed changes
)
# recalculate bf scale
results <- results %>%
mutate(
bf.type =
if_else(bf > .9999,
"BF['1,0']",
"BF['0,1']"
),
bf.tran =
if_else(bf > .9999,
bf,
1 / bf
),
bf.tran =
round(
bf.tran,
2
),
bf.tran.dir =
if_else(bf > .9999,
bf.tran,
bf.tran * (-1)
),
bf.lab =
paste0(
"paste(",
"italic(",
bf.type,
")",
", ' = ",
bf.tran,
"')"
)
<<<<<<< Updated upstream
)
write.csv(results,
file = here(
"data/output",
"moderators.csv"
)
)
View(results)
fig.3b <-
ggplot(
data = results,
aes(
x = moderator,
y = fct_rev(outcome),
fill = bf.tran.dir,
label = bf.lab
)
) +
geom_tile(aes(color = cor),
size = 1,
width = .97, height = 0.97
) +
scale_color_gradient2(
low = "red", mid = "white", high = "blue",
midpoint = 0, limits = c(-1, 1),
name = expression("Pearson's " * italic("r"))
) +
scale_fill_gradient2(
high = "#1b7837",
mid = "white",
low = "black",
midpoint = 1,
limits = c(-8, 8),
name = "Bayes factor",
labels = c(
"-4" = expression(BF["0,1"] == 4),
"-2" = expression(BF["0,1"] == 2),
"0" = expression(BF["1,0"] == 1),
"2" = expression(BF["1,0"] == 2),
"4" = expression(BF["1,0"] == 4)
)
) +
geom_text(aes(label = bf.lab),
parse = T,
nudge_y = .25,
size = 3.5
) +
geom_label(
aes(
label = cor.lab,
color = cor
),
parse = T,
nudge_y = -.25,
size = 3.5
) +
theme_classic() +
labs(
y =
expression("Country-level effects of gratitude interventions (" * italic("d") * ")"),
x = "Country-level differences",
fill = expression("Pearson's " * italic("r"))
) +
theme(
axis.line = element_blank(),
axis.ticks = element_blank(),
plot.background = element_blank(),
axis.text.x = element_text(angle = 45, hjust = 1),
legend.title = element_text(size = 10, margin = margin(b = 15)),
legend.key.size = unit(.6, "cm")
)
moderators <- read.csv(file = here("data/output", "moderators.csv"))%>%
filter(moderator == "tightness" | row_number() %in% c(36, 43, 65)
moderators <- read.csv(file = here("data/output", "moderators.csv"))%>%
moderators <- read.csv(file = here("data/output", "moderators.csv"))%>%
filter(moderator == "tightness" | row_number() %in% c(36, 43, 65))
View(moderators)
moderators <- read.csv(file = here("data/output", "moderators.csv"))%>%
filter(moderator == "tightness" | row_number() %in% c(36, 43, 65)) %>% select(outcome:ci.upper)
moderators <- read.csv(file = here("data/output", "moderators.csv"))
tightness_rows <- moderators %>% filter(moderator == "tightness")
specific_rows <- moderators[c(36, 43, 65), ]
moderators_selected <- bind_rows(tightness_rows, specific_rows) %>%
select(outcome:ci.upper)
print(moderators_selected)
moderators <- read.csv(file = here("data/output", "moderators.csv"))
tightness_rows <- moderators %>% filter(moderator == "tightness")
specific_rows <- moderators[c(36, 43, 65), ]
moderators_selected <- bind_rows(tightness_rows, specific_rows) %>%
select(outcome:ci.upper)
moderators <- read.csv(file = here("data/output", "moderators.csv"))
tightness_rows <- moderators %>% filter(moderator == "Tightness")
specific_rows <- moderators[c(36, 43, 65), ]
moderators_selected <- bind_rows(tightness_rows, specific_rows) %>%
select(outcome:ci.upper)
print(moderators_selected)
# Cross-cultural moderators
moderators <- read.csv(file = here("data/output", "moderators.csv"))
specific_rows <- moderators[c(36, 43, 65), ]
tightness_rows <- moderators %>% filter(moderator == "Tightness")
moderators_selected <- bind_rows(specific_rows, tightness_rows) %>%
select(outcome:ci.upper)
print(moderators_selected)
tightness_rows <- moderators %>% filter(moderator == "Tightness") %>% select(-6)
moderators_selected <- bind_rows(specific_rows, tightness_rows) %>%
select(outcome:ci.upper)
print(moderators_selected)
tightness_rows <- moderators %>% filter(moderator == "Tightness")
View(tightness_rows)
tightness_rows <- moderators %>% filter(moderator == "Tightness") %>% slice(1:5)
moderators_selected <- bind_rows(specific_rows, tightness_rows) %>%
select(outcome:ci.upper)
print(moderators_selected)
tightness_rows <- moderators %>% filter(moderator == "Tightness") %>% slice(1:4)
moderators_selected <- bind_rows(specific_rows, tightness_rows) %>%
select(outcome:ci.upper)
print(moderators_selected)
moderators <- read.csv(file = here("data/output", "moderators.csv"))
View(moderators)
specific_rows <- moderators[c(36, 43, 64, 65), ]
tightness_rows <- moderators %>% filter(moderator == "Tightness") %>% slice(1:4)
moderators_selected <- bind_rows(specific_rows, tightness_rows) %>%
select(outcome:ci.upper)
print(moderators_selected)
=======
return(result)
}
# loop through countries and contrasts
results_list <- list()
for (lab_name in unique_labs) {
country_data <- DF %>% filter(country == lab_name)
control_conditions <- unique(country_data$condition[country_data$condition_type == "control"])
intervention_conditions <- unique(country_data$condition[country_data$condition_type == "intervention"])
for (control_cond in control_conditions) {
for (intervention_cond in intervention_conditions) {
results_list[[length(results_list) + 1]] <- compute_effect_sizes(lab_name, control_cond, intervention_cond)
}
}
}
# combine all results
unique_country_results_df <- do.call(rbind, results_list)
View(unique_country_results_df)
write.csv(unique_country_results_df,
file = here(
"data/output",
"unique_country_effect_sizes.csv"
)
)
# open data
df <-
read.csv(file = here(
"data/output",
"unique_country_effect_sizes.csv"
)) %>%
select(country:ss_var)
# list of effect size columns and variance columns
effect_size_columns <- c(
"pa_effect_size", "na_effect_size",
"optimistic_effect_size", "ls_effect_size",
"envy_effect_size", "indebted_effect_size"
)
variance_columns <- c(
"pa_var", "na_var", "optimistic_var",
"ls_var", "envy_var", "indebted_var"
)
# estimate total heterogeneity
m <- lapply(1:length(effect_size_columns), function(i) {
rma.mv(
yi = df[[effect_size_columns[i]]],
V = df[[variance_columns[i]]],
data = df
)
})
m.c <- lapply(1:length(effect_size_columns), function(i) {
rma.mv(
yi = df[[effect_size_columns[i]]],
V = df[[variance_columns[i]]],
random = ~ 1 | country,
data = df
)
})
m.i <- lapply(1:length(effect_size_columns), function(i) {
rma.mv(
yi = df[[effect_size_columns[i]]],
V = df[[variance_columns[i]]],
random = ~ 1 | intervention_condition,
data = df
)
})
# fit models for each pair of effect size and variance
m.ic <- lapply(1:length(effect_size_columns), function(i) {
rma.mv(
yi = df[[effect_size_columns[i]]],
V = df[[variance_columns[i]]],
random = list(~ 1 | intervention_condition, ~ 1 | country),
data = df
)
})
# store the results
names(m.ic) <- paste(effect_size_columns)
# evaluate variance components for each outcome
lapply(m.ic, function(model) {
model$sigma2[2] / model$sigma2[1]
})
# extract tau values
tau_c <- sapply(m.ic, function(model) (model$sigma2[2]))
tau_i <- sapply(m.ic, function(model) (model$sigma2[1]))
# create data frame
tau_df <- data.frame(
effect_size = effect_size_columns,
tau_c = tau_c,
tau_i = tau_i,
tau_ci = tau_c / tau_i
)
View(tau_df)
# extract tau values
tau_c <- sapply(m.ic, function(model) sqrt((model$sigma2[2])))
tau_i <- sapply(m.ic, function(model) sqrt((model$sigma2[1])))
# create data frame
tau_df <- data.frame(
effect_size = effect_size_columns,
tau_c = tau_c,
tau_i = tau_i,
tau_ci = tau_c / tau_i
)
View(tau_df)
>>>>>>> Stashed changes
