---
title: "SensitivityAnalyses"
author: "Nicholas A. Coles, Annabel V. Dang"
description: "Conduct sensistivity analyses comparing only English and quality check data to the full dataset"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Load packages
```{r lib}
#load packages
source("../setup.R")
```

# Open data
```{r}
# fetch survey for english-only data
EN_DF <- readRDS(file = here("data/final-data", "globalgratitude_final_cleaned.Rds")) %>% 
  filter(UserLanguage == "EN")

# fetch survey for quality-check data
QC_DF <- readRDS(file = here("quality-checks/sensitivity-analyses", "QC_globalgratitude_final_cleaned.Rds"))

# list of effect size columns and variance columns
effect_size_columns <- c("pa_effect_size", "na_effect_size",
                         "optimistic_effect_size","ls_effect_size",
                         "envy_effect_size", "indebted_effect_size")

variance_columns <- c("pa_var", "na_var", "optimistic_var",
                      "ls_var", "envy_var", "indebted_var")
```

#Calculate and apply scales
```{r}
# calculate scales
calc_scales <- function(data) {
  data %>% 
    rowwise() %>% 
    mutate(
      # gratitude
      gratitude_mean = mean(c(grateful, appreciative, thankful), na.rm = TRUE),
      
      # positive affect
      pa_mean = mean(c(happy, satisfied, content, joyful, pleased), na.rm = TRUE),
      
      # optimism
      optimistic_mean = mean(c(optimistic, hopeful), na.rm = TRUE),
      
      # negative affect
      na_mean = mean(c(sad, depressed, anxious, nervous), na.rm = TRUE),
      
      # indebtedness
      indebted_mean = mean(c(indebted, obligated), na.rm = TRUE),
      
      # envy
      envy_mean = mean(c(envious, bitter, jealous), na.rm = TRUE),
      
      # life satisfaction
      ls_mean = mean(c(ls_1, ls_2, ls_3, ls_4, ls_5), na.rm = TRUE),
      
      # sense of self
      ss_mean = mean(c(self_image, self_image_circle), na.rm = TRUE)
    ) %>% 
    ungroup() %>% 
    drop_na(gratitude_mean, pa_mean, optimistic_mean, na_mean, 
            indebted_mean, envy_mean, ls_mean, guilty, ladder, ss_mean) %>% 
    
    mutate(country = case_when(
    lab == "POL_01" ~ "Poland",
    lab == "POL_02" ~ "Poland",
    lab == "DNK_01" ~ "Denmark",
    lab == "TUR_01" ~ "Turkey",
    lab == "MYS_01" ~ "Malaysia",
    lab == "USA_01" ~ "United States",
    lab == "USA_02" ~ "United States",
    lab == "USA_02b" ~ "United States",
    lab == "USA_02c" ~ "United States",
    lab == "NGA_01" ~ "Nigeria",
    lab == "NGA_02" ~ "Nigeria",
    lab == "CAN_01" ~ "Canada",
    lab == "FRA_01" ~ "France",
    lab == "AUS_01" ~ "Australia",
    lab == "CHL_01" ~ "Chile",
    lab == "DEU_01" ~ "Germany",
    lab == "GRC_01" ~ "Greece",
    lab == "HUN_01" ~ "Hungary",
    lab == "ISR_01" ~ "Israel",
    lab == "IRL_01" ~ "Ireland",
    lab == "MEX_01" ~ "Mexico",
    lab == "ITA_01" ~ "Italy",
    lab == "PRT_01" ~ "Portugal",
    lab == "BRA_01" ~ "Brazil",
    lab == "NLD_01" ~ "Netherlands",
    lab == "GBR_01" ~ "United Kingdom",
    lab == "ESP_01" ~ "Spain",
    lab == "ZAF_01" ~ "South Africa",
    lab == "KOR_01" ~ "South Korea",
    lab == "SWE_01" ~ "Sweden",
    lab == "IND_01" ~ "India",
    lab == "COL_01" ~ "Colombia",
    lab == "CHN_01" ~ "China",
    lab == "KAZ_01" ~ "Kazakhstan",
    lab == "NOR_01" ~ "Norway",
    lab == "JPN_01" ~ "Japan",
    lab == "GHA_01" ~ "Ghana",
    lab == "THA_01" ~ "Thailand",
    lab == "MKD_01" ~ "Macedonia",
    TRUE ~ NA_character_
  )) %>%
  filter(!is.na(country)) %>% 
  select(country, condition, condition_type, guilty,ladder,gratitude_mean:ss_mean)%>% 
    mutate(
      # recode factors
      condition = factor(condition, levels = c(
        "measure", "events", "int.events",
        "list", "letter", "text", "naikan", "mental.sub", "divine.grat"
      )),
      condition_type = factor(condition_type, levels = c("control", "intervention"))
    )
}

# apply
EN_DF <- calc_scales(EN_DF)

```

# Organize data
```{r}
# create lists
EN_unique_labs <- unique(EN_DF$country)
QC_unique_labs <- unique(QC_DF$country)

condition_names <- c("list", "letter", "text", "naikan", "mental.sub", "divine.grat")
variables <- c(
  "pa_mean", "na_mean", "optimistic_mean", "ls_mean", "ladder",
  "envy_mean", "indebted_mean", "gratitude_mean", "guilty", "ss_mean"
)

```

#Unique intervention vs. control for each country (Each interventions vs. Each control)
```{r}
# Function to compute all effect sizes for a dataset
compute_all_effect_sizes <- function(data, unique_labs, variables) {
  
  # single comparison
  compute_effect_sizes <- function(lab_name, control_cond, intervention_cond) {
    country_data <- data %>% filter(country == lab_name)
    control_subset <- country_data %>% filter(condition == control_cond)
    intervention_subset <- country_data %>% filter(condition == intervention_cond)
    
    # calculate variance
    calc_var <- function(d, n1, n2) {
      se_d <- sqrt((n1 + n2) / (n1 * n2) + d^2 / (2 * (n1 + n2)))
      return(se_d^2)
    }
    
    # loop through each measure
    effects <- sapply(variables, function(measure) {
      d_result <- effsize::cohen.d(
        intervention_subset[[measure]],
        control_subset[[measure]],
        pooled = TRUE,
        hedges.correction = TRUE
      )
      d_value <- d_result$estimate
      var_value <- calc_var(d_value, nrow(control_subset), nrow(intervention_subset))
      c(d_value, var_value)
    })
    
    # split into vectors
    effect_sizes <- effects[1, ]
    variances <- effects[2, ]
    
    # create result 
    result <- data.frame(
      country = lab_name,
      control_condition = control_cond,
      intervention_condition = intervention_cond,
      contrast = paste(control_cond, "vs", intervention_cond),
      as.list(setNames(effect_sizes, paste0(gsub("_mean", "", variables), "_effect_size"))),
      as.list(setNames(variances, paste0(gsub("_mean", "", variables), "_var"))),
      stringsAsFactors = FALSE
    )
    
    return(result)
  }
  
  # loop through countries and contrasts
  results_list <- list()
  
  for (lab_name in unique_labs) {
    country_data <- data %>% filter(country == lab_name)
    control_conditions <- unique(country_data$condition[country_data$condition_type == "control"])
    intervention_conditions <- unique(country_data$condition[country_data$condition_type == "intervention"])
    
    for (control_cond in control_conditions) {
      for (intervention_cond in intervention_conditions) {
        results_list[[length(results_list) + 1]] <- compute_effect_sizes(lab_name, control_cond, intervention_cond)
      }
    }
  }
  
  # combine all results
  results_df <- do.call(rbind, results_list)
  return(results_df)
}

# Run for both datasets
EN_unique_country_results_df <- compute_all_effect_sizes(EN_DF, EN_unique_labs, variables)
QC_unique_country_results_df <- compute_all_effect_sizes(QC_DF, QC_unique_labs, variables)
```

#Create list
```{r}
# list of effect size columns and variance columns
effect_size_columns <- c("pa_effect_size", "na_effect_size",
                         "optimistic_effect_size","ls_effect_size",
                         "envy_effect_size", "indebted_effect_size")

variance_columns <- c("pa_var", "na_var", "optimistic_var",
                      "ls_var", "envy_var", "indebted_var")
```

#Calculate English data tau values 
```{r}
# fit models for each pair of effect size and variance
en.m.ic <- lapply(1:length(effect_size_columns), function(i) {
  rma.mv(yi = EN_unique_country_results_df[[effect_size_columns[i]]],
         V = EN_unique_country_results_df[[variance_columns[i]]],
         random = list(~ 1 | intervention_condition, ~ 1 | country),
         data = EN_unique_country_results_df)})

# store the results
names(en.m.ic) <- paste(effect_size_columns)

# evaluate variance components for each outcome
lapply(en.m.ic, function(model){
   model$sigma2[2] / model$sigma2[1]})

# extract tau values
en_tau_c <- sapply(en.m.ic, function(model) (model$sigma2[2]))
en_tau_i <- sapply(en.m.ic, function(model) (model$sigma2[1]))

```

#Calculate quality-check  data tau values
```{r}
# fit models for each pair of effect size and variance
qc.m.ic <- lapply(1:length(effect_size_columns), function(i) {
  rma.mv(yi = QC_unique_country_results_df[[effect_size_columns[i]]],
         V = QC_unique_country_results_df[[variance_columns[i]]],
         random = list(~ 1 | intervention_condition, ~ 1 | country),
         data = QC_unique_country_results_df)})

# store the results
names(qc.m.ic) <- paste(effect_size_columns)

# evaluate variance components for each outcome
lapply(qc.m.ic, function(model){
   model$sigma2[2] / model$sigma2[1]})

# extract tau values
qc_tau_c <- sapply(qc.m.ic, function(model) (model$sigma2[2]))
qc_tau_i <- sapply(qc.m.ic, function(model) (model$sigma2[1]))

```

#Calculate tau values for all responses
```{r}
#open data
df <- 
  read.csv(file = here("data/output",
                       "unique_country_effect_sizes.csv")) %>% 
  select(country:ss_var)

# Use lapply to fit models for each pair of effect size and variance
m.ic <- lapply(1:length(effect_size_columns), function(i) {
  rma.mv(yi = df[[effect_size_columns[i]]],
         V = df[[variance_columns[i]]],
         random = list(~ 1 | intervention_condition, ~ 1 | country),
         data = df)})

# Store the results with a name reflecting the effect size and variance pair
names(m.ic) <- paste(effect_size_columns)

# evaluate relative importance of variance components for each outcome
lapply(m.ic, function(model){
  model$sigma2[2] / model$sigma2[1]})

# extract tau values
all_tau_c <- sapply(m.ic, function(model) (model$sigma2[2]))
all_tau_i <- sapply(m.ic, function(model) (model$sigma2[1]))

```

#Create tau dataframe
```{r}

# calculate ratios for English tau analyses
en_tau <- data.frame(
  effect_size = effect_size_columns,
  en_c = en_tau_c,
  all_c = all_tau_c,
  c_diff   = all_tau_c - en_tau_c,
  c_ratio  = en_tau_c / all_tau_c,
  en_i = en_tau_i,  
  all_i = all_tau_i,
  i_diff   = all_tau_i - en_tau_i,
  i_ratio  = en_tau_i / all_tau_i,
  en_ci = en_tau_c / en_tau_i,
  all_ci = all_tau_c / all_tau_i,
  stringsAsFactors = FALSE
)

en_tau$ci_diff  = en_tau$all_ci - en_tau$en_ci
en_tau$ci_ratio = en_tau$en_ci / en_tau$all_ci

write.csv(en_tau, 
          file = here('quality-checks/sensitivity-analyses',
                      "EN_tau_sensitivity_analyses.csv"))

#calculate ratios for quality check tau analyses
qc_tau <- data.frame(
  effect_size = effect_size_columns,
  qc_c = qc_tau_c,
  all_c = all_tau_c,
  c_diff   = all_tau_c - qc_tau_c,
  c_ratio  = qc_tau_c / all_tau_c,
  qc_i = qc_tau_i,  
  all_i = all_tau_i,
  i_diff   = all_tau_i - qc_tau_i,
  i_ratio  = qc_tau_i / all_tau_i,
  qc_ci = qc_tau_c / qc_tau_i,
  all_ci = all_tau_c / all_tau_i,
  stringsAsFactors = FALSE
)

qc_tau$ci_diff  = qc_tau$all_ci - qc_tau$qc_ci
qc_tau$ci_ratio = qc_tau$qc_ci / qc_tau$all_ci

write.csv(qc_tau, 
          file = here('quality-checks/sensitivity-analyses',
                      "QC_tau_sensitivity_analyses.csv"))

```

#Pull effect sizes estimate and CI
```{r}
#effect size estimates for quality check data
qc_results <- lapply(qc.m.ic, function(model) {
  est <- as.numeric(coef(model))               # pooled estimate (intercept)
  se  <- sqrt(diag(vcov(model)))[1]            # SE of intercept
  
  ci_lower <- est - 1.96 * se
  ci_upper <- est + 1.96 * se
  
  data.frame(
    qc_estimate = est,
    qc_ci_lower = ci_lower,
    qc_ci_upper = ci_upper
  )
})

qc_results_df <- do.call(rbind, qc_results)
qc_results_df$outcome <- names(qc.m.ic)

qc_results_df <- qc_results_df[, c("outcome", "qc_estimate", "qc_ci_lower", "qc_ci_upper")]

#effect size estimates for all data
results <- lapply(m.ic, function(model) {
  est <- as.numeric(coef(model))               # pooled estimate (intercept)
  se  <- sqrt(diag(vcov(model)))[1]            # SE of intercept
  
  ci_lower <- est - 1.96 * se
  ci_upper <- est + 1.96 * se
  
  data.frame(
    estimate = est,
    ci_lower = ci_lower,
    ci_upper = ci_upper
  )
})

results_df <- do.call(rbind, results)
results_df$outcome <- names(m.ic)

results_df <- results_df[, c("outcome", "estimate", "ci_lower", "ci_upper")]

results_df <- results_df %>% 
  left_join(qc_results_df, by = c("outcome"))

write.csv(results_df, 
          file = here('quality-checks/sensitivity-analyses',
                      "QC_ef_sensitivity_analyses.csv"))

```