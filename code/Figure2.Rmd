---
title: "Figure 2: Variability decomposition"
author: "Nicholas A. Coles"
date: "2025-04-01"
output: html_document
editor_options: 
  chunk_output_type: console
---
Load libraries
```{r lib}
library(tidyverse)
library(metafor)
library(ggExtra)
library(ggplot2)
library(ggrepel)
library(cowplot)
library(purrr)
library(here)
```

Prep data
```{r}
# open data
# specify directory
i_am("code/Figure2.Rmd")

df <- 
  read.csv(file = here("data",
                       "unique_country_effect_sizes.csv")
           ) %>% 
  select(country:ss_var)

# List of effect size columns and variance columns
effect_size_columns <- c("pa_effect_size", "na_effect_size",
                         "optimistic_effect_size","ls_effect_size",
                         "envy_effect_size", "indebted_effect_size")

variance_columns <- c("pa_var", "na_var", "optimistic_var",
                         "ls_var", "envy_var", "indebted_var")

# estimate total heterogeneity
m <- lapply(1:length(effect_size_columns), function(i) {
  rma.mv(yi = df[[effect_size_columns[i]]],
         V = df[[variance_columns[i]]],
         data = df)})

#Calculate I2

calc_I2_from_model <- function(model) {
  Q <- model$QE           
  df <- model$k - model$p
  
  # I^2 formula
  I2 <- if (Q <= df) 0 else ((Q - df) / Q) * 100
  return(round(I2, 1))
}

m.c  <- lapply(1:length(effect_size_columns), function(i) {
  rma.mv(yi = df[[effect_size_columns[i]]],
         V = df[[variance_columns[i]]],
         random = ~ 1 | country,
         data = df)})


m.i  <- lapply(1:length(effect_size_columns), function(i) {
  rma.mv(yi = df[[effect_size_columns[i]]],
         V = df[[variance_columns[i]]],
         random = ~ 1 | intervention_condition,
         data = df)})

# Use lapply to fit models for each pair of effect size and variance (use this for results, annabel)
m.ic <- lapply(1:length(effect_size_columns), function(i) {
  rma.mv(yi = df[[effect_size_columns[i]]],
         V = df[[variance_columns[i]]],
         random = list(~ 1 | intervention_condition, ~ 1 | country),
         data = df)})

# Store the results with a name reflecting the effect size and variance pair
names(m.ic) <- paste(effect_size_columns)

# Apply to each model in your list
I2_list <- sapply(m.ic, calc_I2_from_model)

# Assign names
names(I2_list) <- effect_size_columns

# evaluate relative importance of variance components for each outcome
lapply(m.ic, function(model){
   model$sigma2[2] / model$sigma2[1]})
```

#Calculate country-level and intervention-level descriptives
```{r}
# Apply the operations for each effect size column
d.c <- lapply(effect_size_columns, function(effect_size) {
  
  d.c <- df %>%
    group_by(country) %>%
    summarise(m = mean(.data[[effect_size]]), .groups = "drop") %>%
    
    # add [jittered] y-value to assist with plotting
    mutate(y = 0,
           y = jitter(y, .1)) %>%
    
    # labels most extreme observations (in terms of min and max)
    mutate(label = if_else(m == min(m),
                           true = country,
                           false = ""),
           label = if_else(m == max(m),
                           true = country,
                           false = label)) %>%
    
    # include effect size name for reference
    mutate(effect_size = effect_size)
  
  return(d.c)
})

d.i <- lapply(effect_size_columns, function(effect_size) {
  
  d.i <- df %>%
    group_by(intervention_condition) %>%
    summarise(m = mean(.data[[effect_size]]), .groups = "drop") %>%
    
    # add [jittered] y-value to assist with plotting
    mutate(y = -0.02,
           y = jitter(y, .1)) %>% 
    
    # labels most extreme observations (in terms of min and max)
    mutate(label = if_else(m == min(m),
                           true = intervention_condition,
                           false = ""),
           label = if_else(m == max(m),
                           true = intervention_condition,
                           false = label)) %>%
    
    # include effect size name for reference
    mutate(effect_size = effect_size)
  
  return(d.i)
})

d.c <- bind_rows(d.c)
d.i <- bind_rows(d.i)
```

#Add Tau
```{r}
# Extract tau values
tau_c <- sapply(m.ic, function(model) (model$sigma2[2]))
tau_i <- sapply(m.ic, function(model) (model$sigma2[1]))

# Create data frame
tau_df <- data.frame(
  effect_size = effect_size_columns,
  tau_c = tau_c,
  tau_i = tau_i,
  tau_ci = tau_c / tau_i
)

options(scipen=999)

tau_label <- data.frame(
  effect_size = "positive_effect_size",
  label_1 = I(list(expression(tau[country]))),
  label_2 = I(list(expression(tau[practice])))
)

```

# Create density plots
```{r}
# Create a list of ggplot objects
m.d <- lapply(seq_along(effect_size_columns), function(i) {
  
  effect_size <- effect_size_columns[i]
  model <- m.ic[[i]]
  
  #Add tau
  tau_label <- tau_df$tau_ci[i]
  tau_str <- if (tau_label > 50) "n.s." else round(tau_label, 2)
  
  # Create label
label_text <- if (tau_str == "n.s.") {
  tau_str
} else {
  paste0("= ", tau_str)
}
  
  # Create the plot for each effect size
  plot <- ggplot() +
    
    # overall effect size estimate
    geom_point(aes(x = model$b[1], 
                   y = 5.7),
               shape = 18,
               size = 4,
               color = "grey30") +
    
    # 95% CI of overall effect size estimate
    geom_segment(aes(x = model$ci.lb, 
                     xend = model$ci.ub, 
                     y = 5.7,
                     yend = 5.7),
                 color = "grey30") +
    
    # visual indicator: null effect
    geom_vline(xintercept = 0,
               color = "grey30",
               linetype = 'dotted') +
    
    # density plot: intervention-level sources of heterogeneity
    stat_function(fun = dnorm, 
                  args = list(mean = model$b[1], 
                              sd = sqrt(model$sigma2[1])), 
                  color = "#E64B35") +
    
    # density plot: country-level sources of heterogeneity
    stat_function(fun = dnorm, 
                  args = list(mean = model$b[1], 
                              sd = sqrt(model$sigma2[2])), 
                  color = "#3C5488") +
        # Add tau_ci label
    geom_text(aes(x = 0.7, y = 11.5, label = label_text),
              color = "black", hjust = 1, vjust = 1, size = 4)
  
if (i == 1) {
  plot <- plot +
    # τ[country] on top, blue color
    annotate(
      "text",
      x = 0.5, y = 13,
      label = expression(tau[country]),
      parse = TRUE,
      size = 5,
      hjust = 1,
      vjust = 1,
      color = "#3C5488"
    ) +
    # τ[practice] below, red color
    annotate(
      "text",
      x = 0.5, y = 10,
      label = expression(tau[practice]),
      parse = TRUE,
      size = 5,
      hjust = 1,
      vjust = 1,
      color = "#E64B35"
    ) +
    # Draw a horizontal line between them to mimic fraction bar
    geom_segment(aes(x = 0.28, xend = 0.52, y = 10.2, yend = 10.2),
                 color = "black", size = 0.5)
}
  
  
  # Final formatting
  plot <- plot +
    scale_x_continuous(limits = c(-0.75, 0.75)) +
    scale_y_continuous(limits = c(0, 13)) +
    theme_void()
  
  return(plot)
})


# Check the resulting list of plots
m.d

```

# Plot descriptives
```{r}
# Combine both datasets into one data frame
d.c$dataset <- "d.c"
d.i$dataset <- "d.i"
d.c$intervention_condition <- NA
d.i$country <- NA

d.c.i <- rbind(d.c, d.i)

# clean labels
d.c.i <- d.c.i %>% 
  mutate(label = case_when(
    label == "god.letter" ~ "divine\ngrat",
    label == "hk.list"    ~ "naikan",
    label == "sub"        ~ "mental\nsub",
    TRUE ~ label
    )
    )

# Create a list of 6 plots based on the effect size values
m.p <- lapply(effect_size_columns, function(es) {
  
  # Filter the data for the current effect_size level
  data_subset <- subset(d.c.i, effect_size == es)
  
  # Create the plot for the current effect_size
  ggplot(data_subset) +
    
    # visual indicator: null effect
    geom_vline(xintercept = 0,
               color = "grey30",
               linetype = 'dotted') +
    
    # Add country-level descriptives (for d.c)
    geom_point(data = subset(data_subset, dataset == "d.c"),
               aes(x = m, y = y), 
               color = "#3C5488", alpha = .5) +
    
    # Add labels for country-level
    geom_text_repel(data = subset(data_subset, dataset == "d.c"),
                    aes(x = m, y = y, label = label),
                    color = "#3C5488", alpha = .5, nudge_y = -.005) +
    
    # Add intervention-level descriptives (for d.i)
    geom_point(data = subset(data_subset, dataset == "d.i"),
               aes(x = m, y = y),
               color = "#E64B35", alpha = .5) +
    
    # Add labels for intervention-level
    geom_text_repel(data = subset(data_subset, dataset == "d.i"),
                    aes(x = m, y = y, label = label),
                    color = "#E64B35", alpha = .5, nudge_y = .005) +
    
    # Aesthetics
    theme_classic() +
    theme(axis.title.y = element_blank(),
          axis.title.x = element_blank(),
          axis.text.y = element_blank(), 
          axis.ticks.y = element_blank()) +
    scale_x_continuous(limits = c(-3, 3))
    #labs(x = expression("Cohens " * italic('d')))
})

# Check the resulting list of plots
m.p
```

# combine plots
```{r}
# Combine m.d and m.p into a single list
combined_plots <- mapply(function(plot_d, plot_p) {
  # Combine each pair of plots (one from m.d and one from m.p) into a list
  plot_grid(plot_d, plot_p, ncol = 1, rel_heights = c(.5, 1))
}, m.d, m.p, SIMPLIFY = FALSE)

# combine the plot
grid <-
  plot_grid(combined_plots[[1]], 
          combined_plots[[2]],
          combined_plots[[3]],
          combined_plots[[4]],
          combined_plots[[5]],
          combined_plots[[6]],
          ncol = 2,
          labels = paste0("   ",
                          letters[1:6],
                          ". ",
                          c('Positive affect',
                            'Negative affect',
                            'Optimism',
                            'Life satisfaction',
                            'Envy',
                            'Indebtedness')
                          ),
          label_size = 10,
          label_x = 0,
          hjust = 0,
          vjust = 1.7
          ) 

# add space at bottom
ggdraw() + 
  draw_plot(grid, 0, 0.05, 1, 0.95) +
  draw_label(expression("Cohen's "*italic(d)), 
             x = 0.5, y = 0, vjust = -1, size = 10)

```
#Confidence Intervals
```{r}
#Confidence Intervals
# Loop through each effect size column and get confidence intervals
ci_list <- list()  # initialize a list to store the CIs

for (col in effect_size_columns) {
  # Apply confint() to each model in the list
  ci_list[[col]] <- confint(m.ic[[col]])
}

ci_df <- do.call(rbind, lapply(names(ci_list), function(name) {
  ci <- ci_list[[name]]
  df <- as.data.frame(ci)
  df$effect <- name
  df$term <- rownames(ci)
  return(df)
}))

# Rename the columns
colnames(ci_df)[1:12] <- c("practice_2_estimate", "practice_estimate",
                           "country_2_estimate", "country_estimate",
                           "practice_2_ci_lb", "practice_ci_lb", 
                           "country_2_ci_lb", "country_ci_lb", 
                           "practice_2_ci_ub", "practice_ci_ub", 
                           "country_2_ci_ub", "country_ci_ub")

write.csv(ci_df, 
        file = here('data',
                    "ci_df.csv"))
```
#Sensitivity Analyses
```{r}
en.m.ic.stats <- lapply(en.m.ic, function(model) {
  data.frame(
    effect_size = model$beta,  # Pooled effect size (estimate)
    ci_lower = model$ci.lb,    # Lower bound of the CI
    ci_upper = model$ci.ub,    # Upper bound of the CI
    p_value = model$pval,      # p-value for the effect size
    tau = model$tau2          # tau (between-study variance)
  )
})

# Combine the list of data frames into one data frame
en.m.ic.df <- do.call(rbind, en.m.ic.stats)

# Add the names of the models (effect size columns) as a new column
en.m.ic.df$effect_size_column <- rep(names(m.ic), each = 1)

m.ic.stats <- lapply(m.ic, function(model) {
  data.frame(
    effect_size = model$beta,  # Pooled effect size (estimate)
    ci_lower = model$ci.lb,    # Lower bound of the CI
    ci_upper = model$ci.ub,    # Upper bound of the CI
    p_value = model$pval,      # p-value for the effect size
    tau = model$tau2          # tau (between-study variance)
  )
})

# Combine the list of data frames into one data frame
m.ic.df <- do.call(rbind, m.ic.stats)

# Add the names of the models (effect size columns) as a new column
m.ic.df$effect_size_column <- rep(names(m.ic), each = 1)

en.m.ic.df$language <- "english"
m.ic.df$language <- "all"

combined_df <- rbind(m.ic.df, en.m.ic.df)

write.csv(combined_df, 
          file = here('data',
                      "lang_sensitivity_analysis.csv"))

```

# Pnorm
How many countries exhibit change in pa
```{r}
# PA
100 - 
  pnorm(q = 0, 
        mean = m.ic[["pa_effect_size"]][["b"]],
        sd = m.ic[["pa_effect_size"]][["sigma2"]][[2]] %>% 
          sqrt()
        ) * 100

# NA (note reverse direction -- i.e., not subtracted from 100)
pnorm(q = 0, 
      mean = m.ic[["na_effect_size"]][["b"]],
      sd = m.ic[["na_effect_size"]][["sigma2"]][[2]] %>% 
        sqrt()
      ) * 100

# optimism
100 - 
  pnorm(q = 0, 
        mean = m.ic[["optimistic_effect_size"]][["b"]],
        sd = m.ic[["optimistic_effect_size"]][["sigma2"]][[2]] %>% 
          sqrt()
        ) * 100

# ls
100 - 
  pnorm(q = 0, 
        mean = m.ic[["ls_effect_size"]][["b"]],
        sd = m.ic[["ls_effect_size"]][["sigma2"]][[2]] %>% 
          sqrt()
        ) * 100

# envy
100 - 
  pnorm(q = 0, 
        mean = m.ic[["envy_effect_size"]][["b"]],
        sd = m.ic[["envy_effect_size"]][["sigma2"]][[2]] %>% 
          sqrt()
        ) * 100

# indebted
100 - 
  pnorm(q = 0, 
        mean = m.ic[["indebted_effect_size"]][["b"]],
        sd = m.ic[["indebted_effect_size"]][["sigma2"]][[2]] %>% 
          sqrt()
        ) * 100
```

