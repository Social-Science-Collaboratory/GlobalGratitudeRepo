as.list(setNames(effect_sizes, paste0(gsub("_mean", "", variables), "_effect_size"))),
as.list(setNames(variances, paste0(gsub("_mean", "", variables), "_var"))),
stringsAsFactors = FALSE
)
return(result)
}
# Loop through countries and contrasts
results_list <- list()
for (lab_name in unique_labs) {
country_data <- DF %>% filter(country == lab_name)
control_conditions <- unique(country_data$condition[country_data$condition_type == "control"])
intervention_conditions <- unique(country_data$condition[country_data$condition_type == "intervention"])
for (control_cond in control_conditions) {
for (intervention_cond in intervention_conditions) {
results_list[[length(results_list) + 1]] <- compute_effect_sizes(lab_name, control_cond, intervention_cond)
}
}
}
# Combine all results
unique_country_results_df <- do.call(rbind, results_list)
# Output
print(unique_country_results_df)
# Initialize result list
results_list <- list()
# Get condition pairs
control_conditions <- unique(DF$condition[DF$condition_type == "control"])
intervention_conditions <- unique(DF$condition[DF$condition_type == "intervention"])
# Function to compute effect sizes between two conditions
compute_effect_sizes <- function(control_cond, intervention_cond) {
control_subset <- DF %>% filter(condition == control_cond)
intervention_subset <- DF %>% filter(condition == intervention_cond)
# Compute effect sizes using sapply
effect_sizes <- sapply(variables, function(measure) {
result <- cohen.d(intervention_subset[[measure]], control_subset[[measure]], pooled = TRUE)
return(result$estimate)
})
# Create data frame row
data.frame(
country = "NA",
control_condition = control_cond,
intervention_condition = intervention_cond,
contrast = paste(control_cond, "vs", intervention_cond),
as.list(setNames(effect_sizes, paste0(gsub("_mean", "", variables), "_effect_size"))),
stringsAsFactors = FALSE
)
}
# Loop over condition pairs
for (control_cond in control_conditions) {
for (intervention_cond in intervention_conditions) {
results_list[[length(results_list) + 1]] <- compute_effect_sizes(control_cond, intervention_cond)
}
}
# Combine into one data frame
unique_cond_results_df <- do.call(rbind, results_list)
# Output
print(unique_cond_results_df)
# Nest overall data by country
overall_country_nested <- overall_country_results_df %>%
group_by(country) %>%
nest()
print(overall_country_nested)
# Nest unique data by condition
unique_country_nested <- unique_country_results_df %>%
group_by(country, control_condition, intervention_condition) %>%
nest()
print(unique_country_nested)
# Nest unique data by condition
unique_condition_nested <- unique_cond_results_df %>%
group_by(control_condition, intervention_condition) %>%
nest()
print(unique_condition_nested)
write.csv(overall_results_df,
file = here('data',
"overall_effect_sizes.csv"))
write.csv(overall_country_results_df,
file = here('data',
"overall_country_effect_sizes.csv"))
write.csv(unique_country_results_df,
file = here('data',
"unique_country_effect_sizes.csv"))
write.csv(unique_cond_results_df,
file = here('data',
"unique_cond_effect_sizes.csv"))
i_am("code/Cleaned_Final_Dataset.R")
library(tidyverse)
library(here)
# specify directory
i_am("code/Cleaned_Final_Dataset.R")
# fetch main survey data
data_main <- readRDS(file = here("data", "GlobalGratitude_Final.Rds"))
data_main <- data_main %>%
select(StartDate:pageNo)
# fetch the USA_02b (harmonized) survey data
data_USA_02b <- read.csv(file = here("data", "USA_02b_raw_harmonized.csv"))
data_USA_02b <- data_USA_02b %>%
select(StartDate:pageNo) %>%
rename("events_list" = "control_list")
# fetch the USA_02c survey data
data_USA_02c <- read.csv(file = here("data", "USA_02c.csv"))
data_USA_02c <- data_USA_02c %>% select(StartDate:pageNo)
#match columns
data_main <- data_main %>%
mutate(across(names(data_USA_02c), ~ {
# matching character columns
if (is.character(data_USA_02c[[cur_column()]])) {
return(as.character(.))
}
# matching numeric or integer columns
else if (is.numeric(data_USA_02c[[cur_column()]])) {
return(as.numeric(.))
}
else {
return(.)
}
}))
# read and combine the CSV files
data <- bind_rows(data_main, data_USA_02c)
data <- bind_rows(data, data_USA_02b)
#clean data
data <- data %>%
#removed test links and incomplete surveys
filter(DistributionChannel != "preview",
consent == 1,
Progress >= 95,
lab != "",
condition_type != "NA",
lab != "NA")
# fix known issues
data <- data %>%
# 4/22/2024 TUR_01 used real link for testing purposes
filter(ResponseId != "R_42KUGZSS76NgWH7",
ResponseId != "R_4W4EXfgeyk1rCYF",
ResponseId != "R_45Z862EIfzYcin4",
ResponseId != "R_7BhJx9Ci7THupmF",
ResponseId != "R_42Lv9fg5qi9V9xm",
ResponseId != "R_2kFa26mh78uevnz",
ResponseId != "R_4DRThnH8LgbEvM8",
ResponseId != "R_4r1kAEqQCo1PNn6",
ResponseId != "R_4GQErqyYDlRWVwZ",
ResponseId != "R_4SGF0GCHSHIN0ls",
ResponseId != "R_6Pndj5c7sr1pcU3",
ResponseId != "R_8lQxsY2ITg7HKh1",
ResponseId != "R_8HXsI5PQftiJUYk",
ResponseId != "R_8iVWI3CN49ACiUp",
#6/6/2024 Removed USA_01 duplicate data
ResponseId != "R_6rDfD5u84z6WufT",
#11/21/2024 Removed DZA_01 test data
ResponseId != "R_4ioYJK1zR2FgR4R",
ResponseId != "R_4OvlyOmeTsmLpFn",
ResponseId != "R_4BA1gbglSYnVyDK")
# change the 'incentive' column from "volunteer" to "paid" for NOR_01 participants after 11/19/2024
data <- data %>%
mutate(StartDate = as.POSIXct(StartDate, format = "%m/%d/%Y %H:%M"),
incentive = if_else(lab == "NOR_01" & StartDate > as.POSIXct("11/19/2024 0:00", format = "%m/%d/%Y %H:%M"),
"paid", incentive))
# fix age data where wrong info is inputted
data <- data %>%
mutate(age = if_else(age > 99, 2024 - age, age))
View(data)
library(openxlsx)
library(dplyr)
library(here)
library(openxlsx)
# open data
# specify directory
i_am("code/GlobalGratitude_QualityChecks.Rmd")
# load the workbook
df <- loadWorkbook(file = here("data", "GlobalGratitude_LabSpecificData.xlsx"))
# get sheet names
sheet_names <- names(df)
# remove the first sheet
removeWorksheet(df, sheet = sheet_names[1])
# save to a temp file (because openxlsx needs a file to read from)
temp_file <- tempfile(fileext = "temp_GlobalGratitude_QualityCheck.xlsx")
saveWorkbook(df, temp_file, overwrite = TRUE)
# re-read sheet names after removal
new_sheets <- getSheetNames(temp_file)
#standardize sheet with mismatched columns
USA_02b <- readWorkbook(temp_file, sheet = new_sheets[37])
#standardize sheet with missing column
USA_02c <- readWorkbook(temp_file, sheet = new_sheets[38])
USA_02c$me_attention <- as.character(NA)
#combine sheets 1-36 and 39 into a dataframe
selected_indices <- c(1:36, 39)
selected_sheets <- lapply(selected_indices, function(i) {
readWorkbook(temp_file, sheet = new_sheets[i])
})
combined_df <- bind_rows(selected_sheets) %>%
#column response was accidentally deleted when conducting quality checks
mutate(lab = ifelse(ResponseId == "R_8EFEKmOIkETMemi", "ITA_01", lab)) %>%
filter(!is.na(lab))
#loop over columns in USA_02b and USA_02c to match the types from combined_df
match_column_types <- function(df, reference_df) {
for (col in names(df)) {
#check if the column exists in combined_df
if (col %in% names(reference_df)) {
#match the column type from combined_df
target_type <- class(reference_df[[col]])
#convert the column type in df to match the target type
if (target_type == "numeric") {
df[[col]] <- as.numeric(df[[col]])
} else if (target_type == "character") {
df[[col]] <- as.character(df[[col]])
} else if (target_type == "factor") {
df[[col]] <- as.factor(df[[col]])
} else if (target_type == "logical") {
df[[col]] <- as.logical(df[[col]])
}
}
}
return(df)
}
#apply to USA_02b and USA_02c
USA_02b <- match_column_types(USA_02b, combined_df)
USA_02c <- match_column_types(USA_02c, combined_df)
#final sheets
final_df <- bind_rows(combined_df, USA_02b, USA_02c)
#fix issues with extra spaces
final_df <- final_df %>%
mutate(Category = str_replace(Category, "^no\\s+$", "no")) %>%
mutate(Category = if_else(Category == "No", "no", Category))
country_summary <- final_df %>%
group_by(lab, Category) %>%
summarise(count = n(), .groups = "drop") %>%
group_by(lab) %>%
mutate(percentage = round(count / sum(count) * 100, 1)) %>%
ungroup()
condition_summary <- final_df %>%
group_by(condition, Category) %>%
summarise(count = n(), .groups = "drop") %>%
group_by(condition) %>%
mutate(percentage = round(count / sum(count) * 100, 1)) %>%
ungroup()
View(condition_summary)
View(country_summary)
View(final_df)
library(tidyverse)
library(here)
library(countrycode)
library(cowplot)
library(ggplot2)
library(dplyr)
options(scipen = 999)
i_am('code/Figure1.Rmd')
country.DF <-
# open data
read.csv(here('data',
'unique_country_effect_sizes.csv'
)
) %>%
# select relevant outcomes
select(
pa_effect_size,
na_effect_size,
optimistic_effect_size,
ls_effect_size,
envy_effect_size,
indebted_effect_size,
country) %>%
# summarise
group_by(country) %>%
summarise(across(everything(), mean, na.rm = TRUE))
# specify directory
i_am("code/GlobalGratitude_Visualization.Rmd")
# fetch survey
DF <- readRDS(file = here("data", "GlobalGratitude_Final_Cleaned.Rds"))
View(DF)
library(tidyverse)
library(here)
# specify directory
i_am("code/Cleaned_Final_Dataset.R")
# fetch main survey data
data_main <- readRDS(file = here("data", "GlobalGratitude_Final.Rds"))
data_main <- data_main %>%
select(StartDate:pageNo)
# fetch the USA_02b (harmonized) survey data
data_USA_02b <- read.csv(file = here("data", "USA_02b_raw_harmonized.csv"))
data_USA_02b <- data_USA_02b %>%
select(StartDate:pageNo) %>%
rename("events_list" = "control_list")
# fetch the USA_02c survey data
data_USA_02c <- read.csv(file = here("data", "USA_02c.csv"))
data_USA_02c <- data_USA_02c %>% select(StartDate:pageNo)
#match columns
data_main <- data_main %>%
mutate(across(names(data_USA_02c), ~ {
# matching character columns
if (is.character(data_USA_02c[[cur_column()]])) {
return(as.character(.))
}
# matching numeric or integer columns
else if (is.numeric(data_USA_02c[[cur_column()]])) {
return(as.numeric(.))
}
else {
return(.)
}
}))
# read and combine the CSV files
data <- bind_rows(data_main, data_USA_02c)
data <- bind_rows(data, data_USA_02b)
#clean data
data <- data %>%
#removed test links and incomplete surveys
filter(DistributionChannel != "preview",
consent == 1,
Progress >= 95,
lab != "",
condition_type != "NA",
lab != "NA") %>%
select(StartDate:pageNo) #Remove non-relevant columns
# fix known issues
data <- data %>%
# 4/22/2024 TUR_01 used real link for testing purposes
filter(ResponseId != "R_42KUGZSS76NgWH7",
ResponseId != "R_4W4EXfgeyk1rCYF",
ResponseId != "R_45Z862EIfzYcin4",
ResponseId != "R_7BhJx9Ci7THupmF",
ResponseId != "R_42Lv9fg5qi9V9xm",
ResponseId != "R_2kFa26mh78uevnz",
ResponseId != "R_4DRThnH8LgbEvM8",
ResponseId != "R_4r1kAEqQCo1PNn6",
ResponseId != "R_4GQErqyYDlRWVwZ",
ResponseId != "R_4SGF0GCHSHIN0ls",
ResponseId != "R_6Pndj5c7sr1pcU3",
ResponseId != "R_8lQxsY2ITg7HKh1",
ResponseId != "R_8HXsI5PQftiJUYk",
ResponseId != "R_8iVWI3CN49ACiUp",
#6/6/2024 Removed USA_01 duplicate data
ResponseId != "R_6rDfD5u84z6WufT",
#11/21/2024 Removed DZA_01 test data
ResponseId != "R_4ioYJK1zR2FgR4R",
ResponseId != "R_4OvlyOmeTsmLpFn",
ResponseId != "R_4BA1gbglSYnVyDK")
# change the 'incentive' column from "volunteer" to "paid" for NOR_01 participants after 11/19/2024
data <- data %>%
mutate(StartDate = as.POSIXct(StartDate, format = "%m/%d/%Y %H:%M"),
incentive = if_else(lab == "NOR_01" & StartDate > as.POSIXct("11/19/2024 0:00", format = "%m/%d/%Y %H:%M"),
"paid", incentive))
# fix age data where wrong info is inputted
data <- data %>%
mutate(age = if_else(age > 99, 2024 - age, age))
saveRDS(data,
file = here('data',
"GlobalGratitude_Final_Cleaned.Rds"))
# specify directory
i_am("code/GlobalGratitude_Visualization.Rmd")
# fetch survey
DF <- readRDS(file = here("data", "GlobalGratitude_Final_Cleaned.Rds"))
View(DF)
# open data
df <-
read.csv(file = here("data",
"unique_country_effect_sizes.csv")
) %>%
select(country:ss_var)
# list of effect size columns and variance columns
effect_size_columns <- c("pa_effect_size", "na_effect_size",
"optimistic_effect_size","ls_effect_size",
"envy_effect_size", "indebted_effect_size")
variance_columns <- c("pa_var", "na_var", "optimistic_var",
"ls_var", "envy_var", "indebted_var")
# use lapply to fit models for each pair of effect size and variance
m.ic <- lapply(1:length(effect_size_columns), function(i) {
rma.mv(yi = df[[effect_size_columns[i]]],
V = df[[variance_columns[i]]],
random = list(~ 1 | intervention_condition, ~ 1 | country),
data = df)})
library(tidyverse)
library(here)
library(BayesFactor)
library(metafor)
library(stringr)
options(scipen = 999)
i_am('code/Figure3.Rmd')
# open data
df <-
read.csv(file = here("data",
"unique_country_effect_sizes.csv")
) %>%
select(country:ss_var)
# list of effect size columns and variance columns
effect_size_columns <- c("pa_effect_size", "na_effect_size",
"optimistic_effect_size","ls_effect_size",
"envy_effect_size", "indebted_effect_size")
variance_columns <- c("pa_var", "na_var", "optimistic_var",
"ls_var", "envy_var", "indebted_var")
# use lapply to fit models for each pair of effect size and variance
m.ic <- lapply(1:length(effect_size_columns), function(i) {
rma.mv(yi = df[[effect_size_columns[i]]],
V = df[[variance_columns[i]]],
random = list(~ 1 | intervention_condition, ~ 1 | country),
data = df)})
# store the results with a name reflecting the effect size and variance pair
names(m.ic) <- paste(effect_size_columns)
# evaluate relative importance of variance components for each outcome
lapply(m.ic, function(model){
model$sigma2[2] / model$sigma2[1]})
# compute probability > 0
effect_prob <- function(effect_name, reverse = FALSE) {
mean_val <- m.ic[[effect_name]][["b"]]
sd_val <- sqrt(m.ic[[effect_name]][["sigma2"]][[2]])
prob <- pnorm(q = 0, mean = mean_val, sd = sd_val) * 100
if (reverse) prob else 100 - prob
}
# create the table
distribution_results <- data.frame(
outcome = c("PA", "NA", "Optimism", "Life Satisfaction", "Envy", "Indebtedness"),
distribution = c(
effect_prob("pa_effect_size"),
effect_prob("na_effect_size", reverse = TRUE),
effect_prob("optimistic_effect_size"),
effect_prob("ls_effect_size"),
effect_prob("envy_effect_size", reverse = TRUE),
effect_prob("indebted_effect_size")
),
opposite_distribution = c(
effect_prob("pa_effect_size", reverse = TRUE),
effect_prob("na_effect_size"),
effect_prob("optimistic_effect_size", reverse = TRUE),
effect_prob("ls_effect_size", reverse = TRUE),
effect_prob("envy_effect_size"),
effect_prob("indebted_effect_size", reverse = TRUE)
))
print(distribution_results)
d.c <- lapply(effect_size_columns, function(effect_size) {
d.c <- df %>%
group_by(country) %>%
summarise(m = mean(.data[[effect_size]]), .groups = "drop") %>%
# add [jittered] y-value to assist with plotting
mutate(y = 0,
y = jitter(y, .1)) %>%
# labels most extreme observations (in terms of min and max)
mutate(label = if_else(m == min(m),
true = country,
false = ""),
label = if_else(m == max(m),
true = country,
false = label)) %>%
# include effect size name for reference
mutate(effect_size = effect_size)
return(d.c)
})
d.c <- bind_rows(d.c)
d.c <- d.c %>% select(-y, -label)
mutate_country_results <- d.c %>%
mutate(
is_negative = case_when(
effect_size == "na_effect_size" ~ m > 0,
effect_size == "envy_effect_size" ~ m > 0,
TRUE                            ~ m < 0
)
)
country_results <- mutate_country_results %>%
group_by(effect_size) %>%
summarise(
opposite_countries_count = sum(is_negative, na.rm = TRUE),
opposite_countries_prop = opposite_countries_count/34,
countries = str_c(country[is_negative], collapse = "\n"),
.groups = "drop"
) %>%
rename(outcome = effect_size) %>%
mutate(
outcome = recode(
outcome,
"pa_effect_size"         = "PA",
"na_effect_size"         = "NA",
"optimistic_effect_size" = "Optimism",
"ls_effect_size"         = "Life Satisfaction",
"envy_effect_size"       = "Envy",
"indebted_effect_size"   = "Indebtedness"
)
)
print(country_results)
universality_data <- left_join(distribution_results, country_results, by = "outcome")
View(universality_data)
viz.DF <-
universality_data %>%
# clean factors
mutate(outcome = factor(outcome,
levels = c("PA",
"Optimism",
"NA",
"Indebtedness",
"Life Satisfaction",
"Envy"),
labels = c("Positive affect",
"Optimism",
"Negative affect",
"Indebtedness",
"Life satisfaction",
"Envy")
),
countries = str_replace_all(countries,
"\n",
", ")
)
fig3a <-
ggplot(data = viz.DF,
aes(y = fct_rev(outcome),
x = opposite_distribution,
label = countries)) +
geom_col(alpha = .5,
fill = 'blue') +
geom_text(aes(x = 18),
size = 3,
hjust = 0) +
theme_classic() +
xlim(0,100) +
xlab('theory-inconsistent proportion of estimated distribution') +
ylab('outcome')
fig3a
